{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cnn2_number.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP/0Kqjw2cPF/+w9Qe6P8e5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"T685EpcI2M1F","colab_type":"code","colab":{}},"source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import load_digits\n","import random"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sdetNQev2ez5","colab_type":"code","outputId":"fbae8740-8cf7-4aa2-8166-c50918dede08","executionInfo":{"status":"ok","timestamp":1581044046849,"user_tz":-540,"elapsed":853,"user":{"displayName":"김소영","photoUrl":"","userId":"07209527371816863636"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["x, y = load_digits(return_X_y=True)\n","x.shape, y.shape, set(y)"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((1797, 64), (1797,), {0, 1, 2, 3, 4, 5, 6, 7, 8, 9})"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"XjMYLDzC3W_4","colab_type":"code","outputId":"282ce36c-b9af-4955-9992-68217d5b0d26","executionInfo":{"status":"ok","timestamp":1580344624188,"user_tz":-540,"elapsed":1867,"user":{"displayName":"김소영","photoUrl":"","userId":"07209527371816863636"}},"colab":{"base_uri":"https://localhost:8080/","height":249}},"source":["xx0 = np.concatenate((x[0].reshape((8,8)), x[1].reshape((8,8))), axis=1)\n","xx1 = np.concatenate((x[2].reshape((8,8)), x[3].reshape((8,8))), axis=1)\n","yy0 = y[:2]\n","yy1 = y[2:4]\n","# plt.title(str(yy0))\n","# plt.imshow(xx0)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f547d5e2198>"]},"metadata":{"tags":[]},"execution_count":17},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAWoAAADWCAYAAAD4p8hZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKGoAyBxFDQCZo6gBIHMUNQBk7v8BRHXLQHRlQuUAAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"4GxwDy9H4iy2","colab_type":"code","outputId":"e322ec43-c843-4859-85a9-374670936271","executionInfo":{"status":"ok","timestamp":1580344728813,"user_tz":-540,"elapsed":777,"user":{"displayName":"김소영","photoUrl":"","userId":"07209527371816863636"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["x_train = np.stack((xx0, xx1), 0)\n","y_train = np.stack((yy0, yy1), 0)\n","x_train.shape, y_train.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((2, 8, 16), (2, 2))"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"GKYrXhQ145oO","colab_type":"code","colab":{}},"source":["#전문가 모델\n","class MyModel(keras.Model):\n","  def __init__(self):\n","    super(MyModel, self).__init__()#상속한 클래스의 생성자 호출 \n","    self.opt = tf.optimizers.SGD(learning_rate=0.01)#Stochatic Gradient Descent 확률적 경사 하강\n","    self.conv0 = keras.layers.Conv2D(16, [3,3], padding='same', activation=keras.activations.relu)\n","    self.conv1 = keras.layers.Conv2D(32, [3,3], padding='same', activation=keras.activations.relu)\n","    self.pool0 = keras.layers.MaxPool2D([2,2], padding='same')\n","    self.pool1 = keras.layers.MaxPool2D([2,2], padding='same')\n","    self.flatten = keras.layers.Flatten()\n","    self.dense = keras.layers.Dense(units=10*2)\n","  \n","  def call(self, x):\n","    #x (1797, 64)\n","    x_4d = tf.reshape(x, [-1,8,16,1]) \n","    x_4d = tf.cast(x_4d, tf.float32)\n","    net = self.conv0(x_4d)\n","    net = self.pool0(net)\n","    net = self.conv1(net)\n","    net = self.pool1(net)\n","    net = self.flatten(net)    \n","    h = self.dense(net)\n","    h = tf.reshape(h, [-1,2,10]) # 2:두자리수, 10:10개의 클래스\n","    h = tf.nn.softmax(h, axis=2) \n","    return h\n","\n","  def get_loss(self, y, h):\n","    #학습할때 nan이 발생하는 경우 값을 clip(자르다) (최소값, 최대값) \n","    h = tf.clip_by_value(h, 1e-8, 1 - 1e-8) # h 가 0이나 1이 되지 않도록 하는 안전장치 \n","    cross_entropy = - (y * tf.math.log(h) + (1 - y) * tf.math.log(1 - h)) \n","    loss = tf.reduce_mean(cross_entropy)\n","    return loss\n","\n","  def get_accuracy(self, y, h):    \n","    predict = tf.argmax(h, -1)\n","    self.acc = tf.reduce_mean(tf.cast(tf.equal(y, predict), tf.float32)) # True > 1, False > 0 로 cast\n","\n","  def fit(self, x, y, epoch=1):\n","    # x : (m, 8, 16), y: (m, 2)    \n","    y_hot = tf.one_hot(y, depth=10, axis=-1) # (m, 2, 10)\n","    for i in range(epoch):\n","      with tf.GradientTape() as tape: #경사 기록 장치\n","        h = self.call(x)\n","        loss = self.get_loss(y_hot, h)        \n","      grads = tape.gradient(loss, self.trainable_variables) #경사 계산\n","      self.opt.apply_gradients(zip(grads, self.trainable_variables)) # 가중치에서 경사를 빼기\n","      self.get_accuracy(y, h)\n","      if i%10==0:\n","        print('%d/%d loss:%.3f acc:%.3f'%(i, epoch, loss, self.acc))\n","model = MyModel()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9gMCYk1t6aNv","colab_type":"code","outputId":"71901246-b994-4bac-c2f2-dace82599965","executionInfo":{"status":"ok","timestamp":1580345210649,"user_tz":-540,"elapsed":1582,"user":{"displayName":"김소영","photoUrl":"","userId":"07209527371816863636"}},"colab":{"base_uri":"https://localhost:8080/","height":197}},"source":["model.fit(x_train, y_train, 100)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0/100 loss:0.606 acc:0.000\n","10/100 loss:0.157 acc:0.500\n","20/100 loss:0.033 acc:1.000\n","30/100 loss:0.017 acc:1.000\n","40/100 loss:0.012 acc:1.000\n","50/100 loss:0.009 acc:1.000\n","60/100 loss:0.007 acc:1.000\n","70/100 loss:0.006 acc:1.000\n","80/100 loss:0.005 acc:1.000\n","90/100 loss:0.004 acc:1.000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yE8VtM5b2puh","colab_type":"code","outputId":"1f831c40-1fa4-4db6-da63-75945d96061b","executionInfo":{"status":"ok","timestamp":1580344353826,"user_tz":-540,"elapsed":988,"user":{"displayName":"김소영","photoUrl":"","userId":"07209527371816863636"}},"colab":{"base_uri":"https://localhost:8080/","height":283}},"source":["x0 = x[0].astype(np.uint8).reshape((8,8))\n","plt.imshow(x0, cmap='gray')"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f547da41b00>"]},"metadata":{"tags":[]},"execution_count":10},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"fpqLygam7YMl","colab_type":"text"},"source":["실습해보기<br>\n","훈련:테스트 = 50:50"]},{"cell_type":"code","metadata":{"id":"FF47S0T27Z_t","colab_type":"code","colab":{}},"source":["%tensorflow_version 2.x\n","import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import load_digits\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HCAHZbXt7_w7","colab_type":"code","outputId":"5cfc3c63-b835-4575-edbb-aa074298baa1","executionInfo":{"status":"ok","timestamp":1581044490537,"user_tz":-540,"elapsed":862,"user":{"displayName":"김소영","photoUrl":"","userId":"07209527371816863636"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["x, y = load_digits(return_X_y=True)\n","x.shape, y.shape, set(y)"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((1797, 64), (1797,), {0, 1, 2, 3, 4, 5, 6, 7, 8, 9})"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"VM4HlgKAEtte","colab_type":"code","outputId":"88fc5eba-f6a3-47c9-ad9c-d243927f42ee","executionInfo":{"status":"ok","timestamp":1581044510131,"user_tz":-540,"elapsed":18809,"user":{"displayName":"김소영","photoUrl":"","userId":"07209527371816863636"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["x = np.array([tf.reshape(image, [8,8]) for image in x])\n","x.shape"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1797, 8, 8)"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"wXkfOICi8BCi","colab_type":"code","outputId":"76d38945-5c18-4b64-b50d-6ea733fffffe","executionInfo":{"status":"ok","timestamp":1581044510131,"user_tz":-540,"elapsed":17361,"user":{"displayName":"김소영","photoUrl":"","userId":"07209527371816863636"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["idx = len(x)//2\n","x_train = x[:idx]\n","y_train = y[:idx]\n","x_test = x[idx:-1]\n","y_test = y[idx:-1]\n","x_train.shape, y_train.shape, x_test.shape, y_test.shape, idx"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((898, 8, 8), (898,), (898, 8, 8), (898,), 898)"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"lyT3CdS-HfS4","colab_type":"code","colab":{}},"source":["train_image = []\n","test_image = []\n","train_label = []\n","test_label = []\n","\n","for _ in range(20000):\n","  rnd1 = random.randrange(0, idx-1)\n","  rnd2 = random.randrange(0, idx-1)\n","  train_image.append(tf.reshape(np.stack((x_train[rnd1], x_train[rnd2]), axis=1), [8, -1]))\n","  train_label.append([y_train[rnd1], y_train[rnd2]])\n","\n","for i in range(idx//2):\n","  test_image.append(tf.reshape(np.stack((x_test[i*2], x_test[i*2+1]), axis=1), [8, -1]))\n","  test_label.append(y_test[i*2:i*2+2])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R5FpLUqB1Yda","colab_type":"text"},"source":["데이터 확인"]},{"cell_type":"code","metadata":{"id":"Zgr8XMLRJBeh","colab_type":"code","outputId":"8ea0c8ca-69a7-405f-f82d-833a5cecd6e0","executionInfo":{"status":"ok","timestamp":1581044514655,"user_tz":-540,"elapsed":16339,"user":{"displayName":"김소영","photoUrl":"","userId":"07209527371816863636"}},"colab":{"base_uri":"https://localhost:8080/","height":249}},"source":["plt.title(train_label[104])\n","plt.imshow(train_image[104])"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fcc1c4afb00>"]},"metadata":{"tags":[]},"execution_count":27},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAWoAAADWCAYAAAD4p8hZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"7vI7D2FQ09Jd","colab_type":"code","outputId":"641422e0-269e-4806-fe47-e0cdcb9d94a1","executionInfo":{"status":"ok","timestamp":1581044547942,"user_tz":-540,"elapsed":881,"user":{"displayName":"김소영","photoUrl":"","userId":"07209527371816863636"}},"colab":{"base_uri":"https://localhost:8080/","height":285}},"source":["plt.title(test_label[1])\n","plt.imshow(test_image[1])"],"execution_count":28,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/matplotlib/text.py:1150: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n","  if s != self._text:\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fcc1c440828>"]},"metadata":{"tags":[]},"execution_count":28},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAWoAAADWCAYAAAD4p8hZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzFHUAJA5ihoAMkdRA0DmKGoAyNz/Anrj8yI85O1DAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"fCmGOskEKgPA","colab_type":"code","colab":{}},"source":["train_image = np.array(train_image)\n","test_image = np.array(test_image)\n","train_label = np.array(train_label)\n","test_label = np.array(test_label)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zm3NcyUFK1Vg","colab_type":"code","outputId":"6f328176-6266-4673-f57a-f1e5be1e89ae","executionInfo":{"status":"ok","timestamp":1580353745477,"user_tz":-540,"elapsed":867,"user":{"displayName":"김소영","photoUrl":"","userId":"07209527371816863636"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["train_image.shape, test_image.shape, train_label.shape, test_label.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((10000, 8, 16), (449, 8, 16), (10000, 2), (449, 2))"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"SpU-t2K0LEcX","colab_type":"code","colab":{}},"source":["#전문가 모델\n","class DigitModel(keras.Model):\n","  def __init__(self):\n","    super(DigitModel, self).__init__()#상속한 클래스의 생성자 호출 \n","    # self.lr_schedule = keras.optimizers.schedules.InverseTimeDecay(0.001,\n","    #                                                                decay_steps=1000,\n","    #                                                                decay_rate=1,\n","    #                                                                staircase=False)\n","    self.opt = tf.optimizers.Adam(keras.optimizers.schedules.InverseTimeDecay(0.001,\n","                                                                    decay_steps=1000,\n","                                                                    decay_rate=1,\n","                                                                    staircase=False)) #Stochatic Gradient Descent 확률적 경사 하강\n","    self.conv0 = keras.layers.Conv2D(128, [3,3], padding='same', activation=keras.activations.relu)\n","    self.conv1 = keras.layers.Conv2D(64, [3,3], padding='same', activation=keras.activations.relu)\n","    self.conv2 = keras.layers.Conv2D(32, [3,3], padding='same', activation=keras.activations.relu)\n","    self.conv3 = keras.layers.Conv2D(32, [3,3], padding='same', activation=keras.activations.relu)\n","    self.pool0 = keras.layers.MaxPool2D([2,2], padding='same')\n","    self.pool1 = keras.layers.MaxPool2D([2,2], padding='same')\n","    self.pool2 = keras.layers.MaxPool2D([2,2], padding='same')\n","    self.pool3 = keras.layers.MaxPool2D([2,2], padding='same')\n","    self.flatten = keras.layers.Flatten()\n","    self.l2 = keras.regularizers.l2(l=0.01)\n","    self.dense0 = keras.layers.Dense(units=128, activation=keras.activations.relu)\n","    self.drop = keras.layers.Dropout(0.5)\n","    self.dense1 = keras.layers.Dense(units=10*2)\n","  \n","  def call(self, x):\n","    #x (1797, 64)\n","    x_4d = tf.reshape(x, [-1,8,16,1]) \n","    x_4d = tf.cast(x_4d, tf.float32)\n","    net = self.conv0(x_4d)\n","    net = self.pool0(net)\n","    net = self.conv1(net)\n","    net = self.pool1(net)\n","    net = self.flatten(net)\n","    net = self.dense0(net)\n","    net = self.drop(net) \n","    # net = self.l2(net)   \n","    h = self.dense1(net)\n","    h = tf.reshape(h, [-1,2,10]) # 2:두자리수, 10:10개의 클래스\n","    h = tf.nn.softmax(h, axis=2) \n","    return h\n","\n","  def get_loss(self, y, h):\n","    #학습할때 nan이 발생하는 경우 값을 clip(자르다) (최소값, 최대값) \n","    h = tf.clip_by_value(h, 1e-8, 1 - 1e-8) # h 가 0이나 1이 되지 않도록 하는 안전장치 \n","    cross_entropy = - (y * tf.math.log(h) + (1 - y) * tf.math.log(1 - h)) \n","    loss = tf.reduce_mean(cross_entropy)\n","    return loss\n","\n","  def get_accuracy(self, y, h):    \n","    predict = tf.argmax(h, -1)\n","    is_equal = tf.equal(y, predict)\n","    self.acc = tf.reduce_mean(tf.cast(tf.equal(y, predict), tf.float32)) # True > 1, False > 0 로 cast\n","    self.acc_all = tf.reduce_mean(tf.cast(tf.reduce_all(is_equal, axis=1), tf.float32))\n","\n","\n","  def fit(self, x, y, epoch=1):\n","    # x : (m, 8, 16), y: (m, 2)    \n","    y_hot = tf.one_hot(y, depth=10, axis=-1) # (m, 2, 10)\n","    for i in range(epoch):\n","      with tf.GradientTape() as tape: #경사 기록 장치\n","        h = self.call(x)\n","        loss = self.get_loss(y_hot, h)        \n","      grads = tape.gradient(loss, self.trainable_variables) #경사 계산\n","      self.opt.apply_gradients(zip(grads, self.trainable_variables)) # 가중치에서 경사를 빼기\n","      self.get_accuracy(y, h)\n","      if i%10==0:\n","        print('%d/%d loss:%.3f acc:%.3f'%(i, epoch, loss, self.acc))\n","model = DigitModel()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tb3yR1m4LaAQ","colab_type":"code","colab":{}},"source":["model.fit(train_image, train_label, 400)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Ff20UzbNjjP","colab_type":"code","colab":{}},"source":["# 테스트셋의 성능\n","h = model(test_image)\n","model.get_accuracy(test_label, h)\n","model.acc, model.acc_all"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JYCf4BIWnjkL","colab_type":"code","colab":{}},"source":["class MyModel(keras.Model):\n","  def __init__(self):\n","    super(MyModel, self).__init__() #상속한 클래스의 생성자 호출 \n","    self.opt = tf.optimizers.Adam(learning_rate=0.001) \n","    self.conv0 = keras.layers.Conv2D(128, [3,3], padding='same', activation=keras.activations.relu, input_shape=(8, 16))\n","    self.conv1 = keras.layers.Conv2D(64, [3,3], padding='same', activation=keras.activations.relu)\n","    self.conv2 = keras.layers.Conv2D(32, [3,3], padding='same', activation=keras.activations.relu)\n","    self.conv3 = keras.layers.Conv2D(32, [3,3], padding='same', activation=keras.activations.relu)\n","    self.pool0 = keras.layers.MaxPool2D([2,2], padding='same')\n","    self.pool1 = keras.layers.MaxPool2D([2,2], padding='same')\n","    self.pool2 = keras.layers.MaxPool2D([2,2], padding='same')\n","    self.pool3 = keras.layers.MaxPool2D([2,2], padding='same')\n","    self.flatten = keras.layers.Flatten()\n","    self.l2 = keras.regularizers.l2()\n","    self.dense0 = keras.layers.Dense(units=128, activation=keras.activations.relu)\n","    self.drop = keras.layers.Dropout(0.4)\n","    self.dense1 = keras.layers.Dense(units=2*10)\n","    self.bn = keras.layers.BatchNormalization()\n","  \n","  def call(self, x):\n","    # x (none, 8, 16)\n","    x_4d = tf.reshape(x, [-1,8,16,1]) \n","    x_4d = tf.cast(x_4d, tf.float32)\n","    net = self.conv0(x_4d)\n","    net = self.pool0(net)\n","    net = self.conv1(net)\n","    net = self.pool1(net)\n","    net = self.conv2(net)\n","    net = self.pool2(net)\n","    net = self.flatten(net)\n","    net = self.dense0(net)\n","    net = self.bn(net)\n","    net = self.drop(net)   \n","    h = self.dense1(net)\n","    h = tf.reshape(h, [-1,2,10]) # 2:두자리수, 10:10개의 클래스 (none, 2, 10)\n","    h = tf.nn.softmax(h, axis=2) # (none, 2) \n","    return h\n","\n","model = MyModel()  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yO8LsVG9oj9o","colab_type":"code","colab":{}},"source":["loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n","optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n","\n","train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n","\n","test_loss = tf.keras.metrics.Mean(name='test_loss')\n","test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n","\n","@tf.function\n","def train_step(images, labels):\n","  with tf.GradientTape() as tape:\n","    predictions = model(images)\n","    loss = loss_object(labels, predictions)\n","  gradients = tape.gradient(loss, model.trainable_variables) # loss에 대한 파라미터들의 도함수\n","  # list of (gradients, variables) pairs\n","  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","  train_loss(loss)\n","  train_accuracy(labels, predictions)\n","\n","@tf.function\n","def test_step(images, labels):\n","  predictions = model(images)\n","  t_loss = loss_object(labels, predictions)\n","  \n","  test_loss(t_loss)\n","  test_accuracy(labels, predictions)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MGqLLevqpGWS","colab_type":"code","colab":{}},"source":["train_ds = tf.data.Dataset.from_tensor_slices((train_image, train_label)).shuffle(10000).batch(64)\n","test_ds = tf.data.Dataset.from_tensor_slices((test_image, test_label)).shuffle(10000).batch(64)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EI4vjCdmpSGa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"11f1b383-10f3-4543-cea0-8c4db38f1ab0","executionInfo":{"status":"ok","timestamp":1581047446268,"user_tz":-540,"elapsed":654856,"user":{"displayName":"김소영","photoUrl":"","userId":"07209527371816863636"}}},"source":["EPOCHS = 1000\n","\n","for epoch in range(EPOCHS):\n","\n","  for images, labels in train_ds:\n","    train_step(images, labels)\n","\n","  for test_images, test_labels in test_ds:\n","    test_step(test_images, test_labels)\n","\n","  template = '에포크: {}, 손실: {}, 정확도: {}, 테스트 손실: {}, 테스트 정확도: {}'\n","\n","  if epoch % 10 == 0:\n","    print (template.format(epoch+1,\n","                         train_loss.result(),\n","                         train_accuracy.result()*100,\n","                         test_loss.result(),\n","                         test_accuracy.result()*100))"],"execution_count":58,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layer my_model_5 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n","\n","If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n","\n","To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n","\n","에포크: 1, 손실: 2.2599027156829834, 정확도: 15.930000305175781, 테스트 손실: 2.1799135208129883, 테스트 정확도: 19.265033721923828\n","에포크: 11, 손실: 1.0210870504379272, 정확도: 72.29522705078125, 테스트 손실: 1.0404301881790161, 테스트 정확도: 70.46973419189453\n","에포크: 21, 손실: 0.5805092453956604, 정확도: 84.5759506225586, 테스트 손실: 0.6683867573738098, 테스트 정확도: 80.50694274902344\n","에포크: 31, 손실: 0.405892550945282, 정확도: 89.36072540283203, 테스트 손실: 0.5282995700836182, 테스트 정확도: 84.58940887451172\n","에포크: 41, 손실: 0.3121751844882965, 정확도: 91.90377807617188, 테스트 손실: 0.44769394397735596, 테스트 정확도: 86.75104522705078\n","에포크: 51, 손실: 0.25366127490997314, 정확도: 93.47661590576172, 테스트 손실: 0.3978327810764313, 테스트 정확도: 88.08245086669922\n","에포크: 61, 손실: 0.2136472761631012, 정확도: 94.5414810180664, 테스트 손실: 0.3643646836280823, 테스트 정확도: 89.05034637451172\n","에포크: 71, 손실: 0.18455618619918823, 정확도: 95.30816650390625, 테스트 손실: 0.33884525299072266, 테스트 정확도: 89.73932647705078\n","에포크: 81, 손실: 0.16245462000370026, 정확도: 95.88666534423828, 테스트 손실: 0.3257828652858734, 테스트 정확도: 90.28018188476562\n","에포크: 91, 손실: 0.14509351551532745, 정확도: 96.33843231201172, 테스트 손실: 0.31293633580207825, 테스트 정확도: 90.72052764892578\n","에포크: 101, 손실: 0.1310943067073822, 정확도: 96.70088958740234, 테스트 손실: 0.3004106283187866, 테스트 정확도: 91.07808685302734\n","에포크: 111, 손실: 0.11956638097763062, 정확도: 96.99810791015625, 테스트 손실: 0.2913021743297577, 테스트 정확도: 91.36419677734375\n","에포크: 121, 손실: 0.10990844666957855, 정확도: 97.24620056152344, 테스트 손실: 0.2894415557384491, 테스트 정확도: 91.60485076904297\n","에포크: 131, 손실: 0.10169894993305206, 정확도: 97.45641326904297, 테스트 손실: 0.2849878966808319, 테스트 정확도: 91.8147201538086\n","에포크: 141, 손실: 0.09463439136743546, 정확도: 97.63681030273438, 테스트 손실: 0.2777835428714752, 테스트 정확도: 91.99007415771484\n","에포크: 151, 손실: 0.08849116414785385, 정확도: 97.7933120727539, 테스트 손실: 0.27569320797920227, 테스트 정확도: 92.14664459228516\n","에포크: 161, 손실: 0.08309941738843918, 정확도: 97.93037414550781, 테스트 손실: 0.2723327875137329, 테스트 정확도: 92.28236389160156\n","에포크: 171, 손실: 0.07832949608564377, 정확도: 98.05140686035156, 테스트 손실: 0.26704975962638855, 테스트 정확도: 92.40091705322266\n","에포크: 181, 손실: 0.07407931238412857, 정확도: 98.15906524658203, 테스트 손실: 0.2624042332172394, 테스트 정확도: 92.5063705444336\n","에포크: 191, 손실: 0.07026809453964233, 정확도: 98.25544738769531, 테스트 손실: 0.25904005765914917, 테스트 정확도: 92.60077667236328\n","에포크: 201, 손실: 0.06683143228292465, 정확도: 98.34223937988281, 테스트 손실: 0.25692662596702576, 테스트 정확도: 92.68468475341797\n","에포크: 211, 손실: 0.06371643394231796, 정확도: 98.42080688476562, 테스트 손실: 0.253615140914917, 테스트 정확도: 92.76116180419922\n","에포크: 221, 손실: 0.06087997555732727, 정확도: 98.49226379394531, 테스트 손실: 0.2526453733444214, 테스트 정확도: 92.83324432373047\n","에포크: 231, 손실: 0.05828617140650749, 정확도: 98.55753326416016, 테스트 손실: 0.2497880756855011, 테스트 정확도: 92.89811706542969\n","에포크: 241, 손실: 0.05590486526489258, 정확도: 98.61738586425781, 테스트 손실: 0.24731658399105072, 테스트 정확도: 92.95576477050781\n","에포크: 251, 손실: 0.053711190819740295, 정확도: 98.67247009277344, 테스트 손실: 0.2457246035337448, 테스트 정확도: 93.0092544555664\n","에포크: 261, 손실: 0.05168379843235016, 정확도: 98.72333526611328, 테스트 손실: 0.2466507852077484, 테스트 정확도: 93.05992889404297\n","에포크: 271, 손실: 0.04980430752038956, 정확도: 98.77044677734375, 테스트 손실: 0.24505384266376495, 테스트 정확도: 93.10726928710938\n","에포크: 281, 손실: 0.048057228326797485, 정확도: 98.81420135498047, 테스트 손실: 0.2457069605588913, 테스트 정확도: 93.1508560180664\n","에포크: 291, 손실: 0.046429090201854706, 정확도: 98.85494995117188, 테스트 손실: 0.24389147758483887, 테스트 정확도: 93.19181823730469\n","에포크: 301, 손실: 0.04490804299712181, 정확도: 98.89299011230469, 테스트 손실: 0.24312341213226318, 테스트 정확도: 93.23043060302734\n","에포크: 311, 손실: 0.04348409175872803, 정확도: 98.92858123779297, 테스트 손실: 0.24214258790016174, 테스트 정확도: 93.26799774169922\n","에포크: 321, 손실: 0.04214813560247421, 정확도: 98.96195983886719, 테스트 손실: 0.24084784090518951, 테스트 정확도: 93.30217742919922\n","에포크: 331, 손실: 0.04089207202196121, 정확도: 98.99332427978516, 테스트 손실: 0.2398134171962738, 테스트 정확도: 93.33328247070312\n","에포크: 341, 손실: 0.039709143340587616, 정확도: 99.0228500366211, 테스트 손실: 0.23849086463451385, 테스트 정확도: 93.36518859863281\n","에포크: 351, 손실: 0.03859320655465126, 정확도: 99.0506820678711, 테스트 손실: 0.23874090611934662, 테스트 정확도: 93.39494323730469\n","에포크: 361, 손실: 0.03753864765167236, 정확도: 99.07698059082031, 테스트 손실: 0.23756150901317596, 테스트 정확도: 93.42213439941406\n","에포크: 371, 손실: 0.03654050827026367, 정확도: 99.10186004638672, 테스트 손실: 0.23768992722034454, 테스트 정확도: 93.44815826416016\n","에포크: 381, 손실: 0.035594429820775986, 정확도: 99.12543487548828, 테스트 손실: 0.23658885061740875, 테스트 정확도: 93.47368621826172\n","에포크: 391, 손실: 0.034696437418460846, 정확도: 99.1478042602539, 테스트 손실: 0.23561006784439087, 테스트 정확도: 93.49791717529297\n","에포크: 401, 손실: 0.03384291008114815, 정확도: 99.16905212402344, 테스트 손실: 0.23522314429283142, 테스트 정확도: 93.5206527709961\n","에포크: 411, 손실: 0.03303072974085808, 정확도: 99.18927001953125, 테스트 손실: 0.23456384241580963, 테스트 정확도: 93.5428237915039\n","에포크: 421, 손실: 0.032256800681352615, 정확도: 99.20852661132812, 테스트 손실: 0.23414169251918793, 테스트 정확도: 93.564208984375\n","에포크: 431, 손실: 0.03151865303516388, 정확도: 99.22689056396484, 테스트 손실: 0.2333766222000122, 테스트 정확도: 93.58538055419922\n","에포크: 441, 손실: 0.030813690274953842, 정확도: 99.24442291259766, 테스트 손실: 0.23355573415756226, 테스트 정확도: 93.60559844970703\n","에포크: 451, 손실: 0.0301397442817688, 정확도: 99.26117706298828, 테스트 손실: 0.23336559534072876, 테스트 정확도: 93.6244125366211\n","에포크: 461, 손실: 0.0294947512447834, 정확도: 99.27720642089844, 테스트 손실: 0.23514552414417267, 테스트 정확도: 93.64265441894531\n","에포크: 471, 손실: 0.028876829892396927, 정확도: 99.29254913330078, 테스트 손실: 0.23516741394996643, 테스트 정확도: 93.66012573242188\n","에포크: 481, 손실: 0.028284374624490738, 정확도: 99.30725860595703, 테스트 손실: 0.23564282059669495, 테스트 정확도: 93.6766357421875\n","에포크: 491, 손실: 0.027715764939785004, 정확도: 99.32136535644531, 테스트 손실: 0.23492078483104706, 테스트 정확도: 93.69270324707031\n","에포크: 501, 손실: 0.027169562876224518, 정확도: 99.33490753173828, 테스트 손실: 0.2351956069469452, 테스트 정확도: 93.7081298828125\n","에포크: 511, 손실: 0.026644615456461906, 정확도: 99.3479232788086, 테스트 손실: 0.23563145101070404, 테스트 정확도: 93.72295379638672\n","에포크: 521, 손실: 0.026139521971344948, 정확도: 99.36044311523438, 테스트 손실: 0.23497802019119263, 테스트 정확도: 93.7372055053711\n","에포크: 531, 손실: 0.02565324865281582, 정확도: 99.37248992919922, 테스트 손실: 0.2355971336364746, 테스트 정확도: 93.7507095336914\n","에포크: 541, 손실: 0.02518463507294655, 정확도: 99.38408660888672, 테스트 손실: 0.23666957020759583, 테스트 정확도: 93.76432800292969\n","에포크: 551, 손실: 0.024732807651162148, 정확도: 99.395263671875, 테스트 손실: 0.23727065324783325, 테스트 정확도: 93.77685546875\n","에포크: 561, 손실: 0.024296944960951805, 정확도: 99.40604400634766, 테스트 손실: 0.2382100224494934, 테스트 정확도: 93.78873443603516\n","에포크: 571, 손실: 0.0238761268556118, 정확도: 99.41644287109375, 테스트 손실: 0.23794445395469666, 테스트 정확도: 93.80058288574219\n","에포크: 581, 손실: 0.023469476029276848, 정확도: 99.4264907836914, 테스트 손실: 0.23736335337162018, 테스트 정확도: 93.81221771240234\n","에포크: 591, 손실: 0.02307640202343464, 정확도: 99.43619537353516, 테스트 손실: 0.23730476200580597, 테스트 정확도: 93.82327270507812\n","에포크: 601, 손실: 0.022696170955896378, 정확도: 99.44557189941406, 테스트 손실: 0.23859746754169464, 테스트 정확도: 93.83358764648438\n","에포크: 611, 손실: 0.02232811227440834, 정확도: 99.45465087890625, 테스트 손실: 0.2382652461528778, 테스트 정확도: 93.84410858154297\n","에포크: 621, 손실: 0.02197176031768322, 정확도: 99.46342468261719, 테스트 손실: 0.23805853724479675, 테스트 정확도: 93.85411834716797\n","에포크: 631, 손실: 0.021626535803079605, 정확도: 99.47193145751953, 테스트 손실: 0.23846745491027832, 테스트 정확도: 93.86380767822266\n","에포크: 641, 손실: 0.021291984245181084, 정확도: 99.48017120361328, 테스트 손실: 0.23800823092460632, 테스트 정확도: 93.87336730957031\n","에포크: 651, 손실: 0.020967507734894753, 정확도: 99.4881591796875, 테스트 손실: 0.2375946044921875, 테스트 정확도: 93.88298034667969\n","에포크: 661, 손실: 0.020652608945965767, 정확도: 99.49590301513672, 테스트 손실: 0.23736706376075745, 테스트 정확도: 93.89246368408203\n","에포크: 671, 손실: 0.020346956327557564, 정확도: 99.50341033935547, 테스트 손실: 0.23793284595012665, 테스트 정확도: 93.90149688720703\n","에포크: 681, 손실: 0.020050236955285072, 정확도: 99.51070404052734, 테스트 손실: 0.23754926025867462, 테스트 정확도: 93.91011047363281\n","에포크: 691, 손실: 0.01976192556321621, 정확도: 99.51778411865234, 테스트 손실: 0.2371405065059662, 테스트 정확도: 93.91862487792969\n","에포크: 701, 손실: 0.019481681287288666, 정확도: 99.52466583251953, 테스트 손실: 0.2368689328432083, 테스트 정확도: 93.92674255371094\n","에포크: 711, 손실: 0.01920921355485916, 정확도: 99.5313491821289, 테스트 손실: 0.23744770884513855, 테스트 정확도: 93.93447875976562\n","에포크: 721, 손실: 0.018944261595606804, 정확도: 99.53784942626953, 테스트 손실: 0.23778998851776123, 테스트 정확도: 93.94230651855469\n","에포크: 731, 손실: 0.018686413764953613, 정확도: 99.54417419433594, 테스트 손실: 0.23762787878513336, 테스트 정확도: 93.95037841796875\n","에포크: 741, 손실: 0.01843547262251377, 정확도: 99.55032348632812, 테스트 손실: 0.23734134435653687, 테스트 정확도: 93.95808410644531\n","에포크: 751, 손실: 0.018191039562225342, 정확도: 99.55631256103516, 테스트 손실: 0.2370142787694931, 테스트 정확도: 93.96513366699219\n","에포크: 761, 손실: 0.017953012138605118, 정확도: 99.56214141845703, 테스트 손실: 0.2381894737482071, 테스트 정확도: 93.97215270996094\n","에포크: 771, 손실: 0.017721042037010193, 정확도: 99.56781768798828, 테스트 손실: 0.2378290444612503, 테스트 정확도: 93.97941589355469\n","에포크: 781, 손실: 0.017494967207312584, 정확도: 99.57335662841797, 테스트 손실: 0.2380286306142807, 테스트 정확도: 93.9863510131836\n","에포크: 791, 손실: 0.01727456972002983, 정확도: 99.57875061035156, 테스트 손실: 0.23767539858818054, 테스트 정확도: 93.99311828613281\n","에포크: 801, 손실: 0.017059646546840668, 정확도: 99.5840072631836, 테스트 손실: 0.2378183752298355, 테스트 정확도: 93.99971008300781\n","에포크: 811, 손실: 0.01684991456568241, 정확도: 99.58914184570312, 테스트 손실: 0.23746532201766968, 테스트 정확도: 94.005859375\n","에포크: 821, 손실: 0.016645237803459167, 정확도: 99.5941390991211, 테스트 손실: 0.2377728372812271, 테스트 정확도: 94.0118637084961\n","에포크: 831, 손실: 0.016445444896817207, 정확도: 99.59902954101562, 테스트 손실: 0.23758089542388916, 테스트 정확도: 94.01786041259766\n","에포크: 841, 손실: 0.016250353306531906, 정확도: 99.60379791259766, 테스트 손실: 0.23725251853466034, 테스트 정확도: 94.02397918701172\n","에포크: 851, 손실: 0.016059787943959236, 정확도: 99.60845184326172, 테스트 손실: 0.23778879642486572, 테스트 정확도: 94.02982330322266\n","에포크: 861, 손실: 0.015873659402132034, 정확도: 99.61299896240234, 테스트 손실: 0.23788562417030334, 테스트 정확도: 94.035400390625\n","에포크: 871, 손실: 0.015691785141825676, 정확도: 99.61743927001953, 테스트 손실: 0.2379162460565567, 테스트 정확도: 94.04122924804688\n","에포크: 881, 손실: 0.015513993799686432, 정확도: 99.62178802490234, 테스트 손실: 0.23775231838226318, 테스트 정확도: 94.04679870605469\n","에포크: 891, 손실: 0.015340163372457027, 정확도: 99.62602996826172, 테스트 손실: 0.23757025599479675, 테스트 정확도: 94.05225372314453\n","에포크: 901, 손실: 0.015170148573815823, 정확도: 99.63018035888672, 테스트 손실: 0.23742714524269104, 테스트 정확도: 94.05733489990234\n","에포크: 911, 손실: 0.015003870241343975, 정확도: 99.63423919677734, 테스트 손실: 0.2372332364320755, 테스트 정확도: 94.06254577636719\n","에포크: 921, 손실: 0.01484117191284895, 정확도: 99.6382064819336, 테스트 손실: 0.23704810440540314, 테스트 정확도: 94.0677719116211\n","에포크: 931, 손실: 0.014681967906653881, 정확도: 99.64208984375, 테스트 손실: 0.23706547915935516, 테스트 정확도: 94.07276153564453\n","에포크: 941, 손실: 0.014526103623211384, 정확도: 99.64590454101562, 테스트 손실: 0.23688295483589172, 테스트 정확도: 94.07752227783203\n","에포크: 951, 손실: 0.01437351293861866, 정확도: 99.64962005615234, 테스트 손실: 0.23677201569080353, 테스트 정확도: 94.0824203491211\n","에포크: 961, 손실: 0.014224067330360413, 정확도: 99.65326690673828, 테스트 손실: 0.23656615614891052, 테스트 정확도: 94.08721923828125\n","에포크: 971, 손실: 0.01407769788056612, 정확도: 99.6568374633789, 테스트 손실: 0.2363162338733673, 테스트 정확도: 94.0919189453125\n","에포크: 981, 손실: 0.013934317976236343, 정확도: 99.66033935546875, 테스트 손실: 0.23640039563179016, 테스트 정확도: 94.09651947021484\n","에포크: 991, 손실: 0.013793818652629852, 정확도: 99.66376495361328, 테스트 손실: 0.23628464341163635, 테스트 정확도: 94.10102844238281\n"],"name":"stdout"}]}]}